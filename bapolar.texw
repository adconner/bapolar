\documentclass{amsart}
\usepackage{amsmath,amssymb,amsthm,mathrsfs,microtype}
\usepackage{minted}
\usepackage[margin=1in]{geometry}

\newtheorem{theorem}{Theorem}
\newtheorem{observation}[theorem]{Observation}
\newtheorem{lemma}[theorem]{Lemma}

\newcommand{\CC}{\mathbb{C}}
\newcommand{\ot}{\otimes}

\newcommand{\abs}[1]{\lvert #1 \rvert}
\newcommand{\Abs}[1]{\left\lvert #1 \right\rvert}
\newcommand{\norm}[1]{\lVert #1 \rVert}

\newcommand{\code}[1]{\mintinline{python}{#1}}

\DeclareMathOperator{\LT}{LT}
\DeclareMathOperator{\LM}{LM}
\DeclareMathOperator{\Lm}{\textsc{Lm}}
\DeclareMathOperator{\ltcoeff}{\textsc{LtCoeff}}
\DeclareMathOperator{\wt}{wt}

\title{Border apolarity implementation}
\author{Austin Conner}

\begin{document}
\maketitle
\section{Introduction}\label{sec:intro}
Given a tensor $T \in A \ot B\ot C$, a natural number $r$, and a solvable
connected Lie group $B \subset \operatorname{GL}(A) \times \operatorname{GL}(B)
\times \operatorname{GL}(C)$ stabilizing $T$, the routines of this file seek to
practically implement complete enumeration of multigraded ideals $I\subset
\operatorname{Sym}(A^* \oplus B^* \oplus C^*)$ satisfying
\begin{enumerate}
\item \label{Bfixed} I is $B$-fixed
\item \label{inTperp} $I \subset T^\perp$
\item \label{codim} The $(ijk)$-graded component of $I$, $I_{ijk} \subset S^i(A^*)\ot S^j(B^*)
\ot S^k(C^*)$, has codimension $\min (r, \dim S^i(A^*)\ot S^j(B^*) \ot
S^k(C^*))$.
\end{enumerate}

Such ideals may occur in positive dimensional families, so more precisely we
wish to enumerate computational descriptions of families of ideals which
together exhaust all ideals satisfying the conditions. The kinds of families of
ideals manipulated by the program are described in \S\ref{sec:representation}
and called \emph{representable}. A representable family of ideals $I_t$ always
satisfies conditions (\ref{Bfixed}) and (\ref{inTperp}) above, and $t$ ranges
over an affine variety. Hence, the work of the program is to enumerate an
exhaustive list of representable families satisfying condition (\ref{codim}). 
The program proceeds by exhaustively enlarging ideals so that condition (\ref{codim}) is
satisfied one multidegree at a time.

\subsection{Overview of algorithm}

The fundamental unit of computation is the routine \code{enumerate_tm} which
does this enlargement in a given multigraded component. More precisely, it takes
as input a representable family $I_t$ and a multidegree $(ijk)$ and produces a list of
representable families which together exhaust the set of ideals which (i)
are of the form $I_t + (p_1,\ldots,p_l)$ for some $t$ and $p_1,\ldots,p_l \in
S^i(A^*)\ot S^j(B^*) \ot S^k(C^*)$ and (ii) satisfy condition (\ref{codim}) in
multidegree $(ijk)$. Moreover, the families output by \code{enumerate_tm} are
parameterized combinatorially by the set of leading monomials of polynomials in
this multidegree. In principle, this routine already is sufficient to perform
full ideal enumeration, as one could fix a list of all the multidegrees and for
each $k$ compute all representable families satisfying (\ref{codim}) in the
first $k$ multidegrees with generators only in these multidegrees. Eventually,
by the Hilbert basis theorem,
% is there more here, some theorem about hilbert functions?
condition (\ref{codim}) will be satisfied in all codimensions. This stopping
condition can be checked computationally by computing the Hilbert series of the
common leading term ideal of the family. 
% this is a little imprecise, maybe I really have to pass to irreducible
% parameter spaces and generic leading term ideals to fully justify the stopping
% condition
In practice, we make the enumeration
more tractable via the use of two other routines \code{enumerate_tm_bounded} and
\code{ideal_sum}.

The routine \code{enumerate_tm_bounded} takes as input a multidegree $(ijk)$ and
a representable family $I_t$, say where $t$ ranges over $X$. It computes the
family restricted to the subvariety $Y\subset X$ on which $\operatorname{codim}
(I_t)_{ijk} \le r$. In other words, $t$ is restricted to the subvariety on which
a necessary condition holds for $I_t$ in the family to be contained in one
satisfying (\ref{codim}). We speak of \code{enumerate_tm_bounded} as applying
the $(ijk)$ test.
The routine \code{ideal_sum} takes a pair of families $I_t$ and $J_s$, say where
$t\in X$ and $s\in Y$, and computes the family $I_t + J_s$, where $(t,s) \in X
\times Y$.

A typical approach for border rank lower bounds is to enumerate representable
families satisfying (\ref{codim}) in multidegree (110) and to apply the (210)
and (120) tests to each family. Call the results of this the (110)
\emph{candidates}. For showing $2\times 2$ matrix multiplication has border rank
at least 7, this is already enough, as there are no candidates already at this
stage when $r=6$. If we need to continue, we similarly compute the (101) and
(011) candidates. For each triple of candidates in these multidegrees, we add
them together and apply the (111) test. This approach shows that $3\times 3$
matrix multiplication and the $3\times 3$ determinant polynomial each have 
border rank at least 17.

\subsection{Input description}\label{sec:input}
Choose bases of $A$, $B$ and $C$ consisting of weight vectors under the
torus of $B$. The data of the action of $B$ then consists of the weights of
these distinguished basis vectors along with a faithful representation $\mathfrak{n} \to
\mathfrak{gl}(A) \oplus \mathfrak{gl}(B)\oplus \mathfrak{gl}(C)\subset
\mathfrak{gl}(A\oplus B\oplus C)$ of the nilradical $\mathfrak{n}$ of the lie
algebra of $B$. Concretely, $\mathfrak{n}$ and its representation is described
by distinguishing lie algebra generators $x_1,\ldots,x_k \in \mathfrak{n}$ and
providing the matrices of the corresponding actions on the distinguished basis
of $A\oplus B\oplus C$. This data describing the action of $B$ along with $T$
expressed in the distinguished bases is the input to the routines in this file.
% TODO make code correspond to this paragraph. Namely, xs act on primal not on dual

\subsection{Representable families of ideals}\label{sec:representation}

\newcommand{\ba}{\textbf{a}} 
\newcommand{\bb}{\textbf{b}}
\newcommand{\bc}{\textbf{c}} 

We wish to describe a computationally efficient
representation of Borel fixed multigraded ideals which may depend on parameters.
At core, ideals will be
represented by Gr\"obner bases with homogeneous generators taken from
$T^\perp$. Thus, condition (\ref{inTperp}) will be satisfied by construction. 
The issues which must be addressed then are how to efficiently require ideals
are Borel fixed and how to represent parameter
dependence. 


\subsubsection{Borel fixed condition} 
\label{sec:borelfixed}
Immediately we can ensure ideals considered are torus invariant by
insisting generators are weight vectors. In other words the ideals under
consideration are homogeneous with respect to a finer grading determined by the
torus weights and can be taken to be generated homogeneously.

Now to enforce condition (\ref{Bfixed}), it is necessary and sufficient to
insist that the ideal is closed under the Lie algebra action of the generators
$x_1,\ldots,x_k \in \mathfrak{n}$. One could address this issue in a simple way:
Whenever a new ideal is constructed, recursively consider all pairs of current
ideal generators with Lie algebra generators $x_1,\ldots,x_k$ and adjoin as a
generator the corresponding raising. However, this approach is both slow and
error prone if one tries to make it efficient. We would like to arrange that
Gr\"obner basis computations in the underlying CAS automatically adjoin new
raisings of generators which may be needed. This would remove this burden from
us and also affords us the benefit of the significant engineering effort already
expended to do this kind of task quickly.

Conveniently, this is possible after making some observations. Let $\ba = \dim
A$, $\bb = \dim B$, $\bc = \dim C$, and write $a_1,\ldots, a_\ba \in A^*$,
$b_1,\ldots, b_\bb \in B^*$, $c_1,\ldots, c_\bc \in C^*$ for dual bases to the
distinguished bases of \S\ref{sec:input}. For notational convenience, also let
$n = \ba+\bb+\bc$ and for $1\le i\le n$, let $y_i$ range over the $n$ elements $
a_1,\ldots,a_\ba,b_1,\ldots,b_\bb,c_1,\ldots,c_\bc$. Let $x\in \mathfrak{n}$,
and suppose $x . y_j = \sum_{i=1}^\ba x_{ij} y_i$. The matrix $[x_{ij}]$ is
block diagonal with three diagonal blocks corresponding to the variables of
$A^*$, $B^*$, and $C^*$. Define the associated element $\bar x = \sum_{i,j=1}^n
x_{ij} y_i \partial_{y_j} $ in the Weyl algebra
$W=\CC[y_1,\ldots,y_n,\partial_{y_1},\ldots,\partial_{y_n}]$.

\begin{observation}\label{lieaction}
  Suppose $x\in \mathfrak{n}$ and $p \in \CC[y_1,\ldots,y_n] \subset W$.
  Then, in $W$, $\bar x p - p \bar x = x . p$.
\end{observation}
\begin{observation}\label{envelopingalgebra}
  If $x_1,\ldots,x_k$ generate $\mathfrak{n}$, then the subring of $W$ generated
  by $\bar x_1,\ldots, \bar x_k$ is the universal enveloping algebra
  $U(\mathfrak{n})$ 
\end{observation}

Let $S$ denote the subalgebra of $W$ generated by the $y_i$ and $\bar x_i$,
where $x_i$ generate $\mathfrak{n}$, and let $R = \CC[y_1,\ldots,y_n] \subset S$
denote the commutative polynomial ring. Then from Observation \ref{lieaction} it follows

\begin{observation}
  If $J \subset S$ is a two sided ideal, then $J\cap R$ is closed under the
  action of $\mathfrak{n}$. Moreover, if $I\subset R$ is an ideal then $SIS \cap R$ is the
  smallest $\mathfrak{n}$-fixed ideal containing $I$.
\end{observation}

In particular, to compute with only with Borel fixed multigraded ideals, it
suffices to work with two sided ideals of $S$ homogeneously generated by
elements of $R$. How do we work with such objects computationally? If now we
distinguish a vector space basis $x_1,\ldots, x_k$ of $\mathfrak{n}$, then $S$
is the noncommutative polynomial ring with indeterminants
$y_1,\ldots,y_n,x_1\ldots,x_k$ subject to the commutator relations $x_iy_j =
y_jx_i + x_i. y_j$, $x_ix_j = x_jx_i + [x_i,x_j]$, and the $y_i$ commute with
each other. This data makes $S$ into what is called a $G$-algebra
\cite{levandovsky}, and,
in particular, efficient implementations exist for computing Gr\"obner bases of
two sided ideals of $S$.

% There is an element in the Weyl algebra in the indeterminants
% $ a_1,\ldots,a_\ba,b_1,\ldots,b_\bb,c_1,\ldots,c_\bc$ corresponding to any
% element of $\mathfrak{n}$. Namely,

% $\mathbb{C}[a_1,\ldots,a_\ba,b_1,\ldots,b_\bb,c_1,\ldots,c_\bc,
% \partial_{a_1}, \ldots, \partial_{a_\ba},
% \partial_{b_1}, \ldots, \partial_{b_\bb},
% \partial_{c_1}, \ldots, \partial_{c_\bc} ]$ 

\subsubsection{Representation of parameterized families}
  \label{sec:parameterized}

Generators of a parameterized family $I_t \subset \CC[y_1,\ldots,y_n]$ are
essentially represnted as having coefficients in some other polynomial ring, and
we imagine the family to be parameterized by the different choices of values for
the new variables. In other words, a parameterized family $I_t$ is represented
by an ideal $J \subset \CC[y_1,\ldots,y_n,t_1,\ldots,t_k]$. We take the new
indeterminants $t_1,\ldots,t_k$ to have degree zero, so that a homogeneous
family $I_t$ is represented by a homogeneous ideal $J$.

For an family $I_t$ represented by $J$, if $t$ takes a value outside the variety
$X$ cut out by $J\cap \CC[t_1,\ldots,t_k]$, then by the Nullstellensatz $I_t =
(1)$. We therefore adopt the convention that the family $I_t$ corresponding to
$J$ takes parameter values $t$ only inside $X$.
In view of this convention, we say that a family $J'$ is a \emph{restriction} of
$J$ if, for $I' = J'\cap \CC[t_1,\ldots,t_k]$, we have $J' =
J+\CC[y_1,\ldots,y_n,t_1,\ldots,t_k]I'$. Hence, $J$ and $J'$ represent the same
family, but $J'$ is restricted to $X' = V(I') \subset X$.
For $t\in X$,
write $J(t)$ for the ideal in $\CC[y_1,\ldots,y_n]$ resulting from substituting
$t$ into each element of $J$, that is, $J(t)$ is the ideal $I_t$ of the
corresponding family. 

% TODO note semicontinuity of codim in t?

Fix a monomial ordering on $\CC[y_1,\ldots,y_n]$.
Condition (\ref{codim})
requires us to reason about Hilbert series of homogeneous ideals, and we will do
so by reducing to Hilbert series of the leading term ideal with respect to this
monomial ordering. 
We wish to choose a monomial
order on $\CC[y_1,\ldots,y_n,t_1,\ldots,t_k]$ so that the leading term ideal of
$J$ gives us information about the leading term ideals of each $J(t)$ in the
corresponding family.
It will be sufficient for our purposes to require that the monomial order is a block order
with the variable block $y_1,\ldots,y_n$ greater than the variable block
$t_1,\ldots,t_k$. In other words, we require that $y^{\alpha_1} t^{\beta_1} >
y^{\alpha_2} t^{\beta_2}$ if and only if $y^{\alpha_1} > y^{\alpha_2} $ or
$y^{\alpha_1} = y^{\alpha_2}$ and $t^{\beta_1} > t^{\beta_2}$ for some
fixed monomial order on just the $t$ monomials. 

This monomial order has the effect of grouping together monomials
with the same exponent in the variables $y_1,\ldots,y_n$, so it is possible to 
read off the coefficient of a leading monomial in the variables $y_1,\ldots,y_n$
as a polynomial in $\CC[t_1,\ldots,t_k]$. More precisely, for $p\in
\CC[y_1,\ldots,y_n,t_1,\ldots,t_k]$, if $\LM(p) = y^\alpha t^\beta$, write
$\Lm(p) = y^\alpha$, and denote by $\ltcoeff(p) \in
\CC[t_1,\ldots,t_k]$ the coefficient of $y^\alpha$ in $p$.

We need to understand how $\LT(J(t))$ can depend on $t$. Say that a
monomial $y^\alpha$ is \emph{trivially missing} if $y^\alpha t^\beta \in \LT(J)$
only if $t^\beta \in \LT(J)$. 
If $J\cap \CC[t_1,\ldots,t_k]$ is prime (maximal), for
instance, then $y^\alpha$ is trivially missing if and only if $y^\alpha \notin
\LT(J(t))$ for generic $t$ (for the unique $t$). 

% two concerns here (1) how to restrict t to that subvariety so that y^alpha not
% in LT(J(t)) (2) what happens under restriction


% need restriction to not  break test already done. actually not a soundness issue though
% (completeness)
% can always just apply necessary tests
% prove all ideals occur at some point in this process also need

We need the following:
\begin{observation}\label{missing}
  Let $J'$ be a restriction of $J$. % other conditions?
  If $s$ of the largest $m$ monomials in multidegree $(ijk)$ are trivially
  missing from $J$, then at least $s$ of the largest $m$ monomials are trivially
  missing from $J'$.

  In particular, if $s$ of the largest $m$ monomials are trivially missing in
  $J$, then at least $s$ of the largest $m$ monomials are not contained in
  $\LM(J(t))$ for any $t$.
\end{observation}
\begin{proof}
  Let $l = m-s$, $I = J\cap \CC[t_1,\ldots,t_k]$, and $I' = J'\cap
  \CC[t_1,\ldots,t_k]$.
  Suppose $p_1,\ldots,p_l\in J'$ have $\Lm(p_i)$ pairwise disjoint among the
  largest $m$ monomials of multidegree $(ijk)$ and $\ltcoeff(p_i) \notin I'$.
  It will be sufficient to show
  there exist $l$ polynomials satisfying the same conditions with $J'$ and $I'$
  replaced by $J$ and $I$, respectively. For each $i\le l$, there is $q_i$
  in the extension of $I'$ so that $p_i' = p_i+q_i \in J$. 
  We may assume $\ltcoeff(p_i') \notin I$.

  If $\Lm(p_i')$ are not pairwise distinct, suppose $\Lm(p_i') = \Lm(p_j')$ with
  $\Lm(p_i) > \Lm(p_j)$.
  Replace $p_i'$ with $p_i' \ltcoeff(p_j') - p_j' \ltcoeff(p_i')$.
  TODO maybe assume $I'$ maximal and argue we never get zero during this
  procedure
  % procedure assuming I' is maximal and considering smallest (I')^m
  % coefficients in

  % There are no $\CC[t_1,\ldots,t_k]$ syzygies between the $p_i'$. Indeed,
  % suppose $c_1p_1' + \cdots c_l p_l' = 0$, $c_i \in \CC[t_1,\ldots,t_k]$.
  % The coefficient of $\Lm(p_1)$ in each of $c_ip_i'$, $i > 1$ is contained in
  % $I'$, hence also $c_1p_1' \in I'$. Since $I'$ is prime, we have $c_1\in I'$.
  % We may argue similarly by induction that all $c_i \in I'$.
\end{proof}

Let $M$ be a set of monomials of multidegree $(ijk)$.
If a family $J$ contains a polynomial $p$ with $\LT(p) = y^\alpha$ for each
$y^\alpha\in M$ and all monomials of multidegree $(ijk)$ not in $M$
are trivially missing, then in view of observation \ref{missing}, all
ideals $J(t)$ have precisely the monomials of $M$ in the leading
term ideal in multidegree $(ijk)$. 
This fact is the basis of how \code{enumerate_tm} 
will enumerate all ideals of required codimension in a prescribed multidegree.
Central to this is the ability to restrict a given family to one where a
certain monomial is trivially missing.
If $y^\alpha$ is not trivially missing from $J$, then there is
$p\in J$ so that $\Lm(p) = y^\alpha$ and $\ltcoeff(p) \notin J\cap
\CC[t_1,\ldots,t_k]$. 
In particular, in order that a restriction $J'$ of $J$ have $y^\alpha$ trivially
missing, it is necessary for $\ltcoeff(p) \in J'$. Hence, the minimal
restriction $J'$ of $J$ where $y^\alpha$ is trivially missing can be computed by
recursively adjoining such leading terms to $J$. This is carried out in \code{minimal_relations_killing_leading_term}.



% Given a parameterized family $J(t)$ and a monomial $y^\alpha$, let $J_\alpha^0 =
% (\ltcoeff(p) \mid \Lm(p) \le \alpha \text{ and $p$ appears in the reduced
% Gr\"obner basis of $J$}) \subset \CC[t_1,\ldots,t_k]$. For instance, $J_0^0 =
% \CC[y_1,\ldots,y_n] \cap J$ is the set of defining equations of the domain of
% $t$.
% It is clear that $t \in V(J_\alpha^0)$ is a necessary condition that $y^\alpha
% \notin \LT(J(t))$. It need not be sufficient, as under some parameter values,
% $\ltcoeff$'s of polynomials in the ideal may vanish, promoting other monomials
% dividing $y^\alpha$ to be leading. % this might be misleading

% Write $J_\alpha = J+J_\alpha^0$, which corresponds to restricting the family $J(t)$
% to $t\in V(J_\alpha^0)$. We can iterate this restriction process until
% stabilization to obtain $J_\alpha^* = J_{\alpha\cdots\alpha}$.

% However, we have the following, which will be sufficient for our purposes.

% \begin{observation}
%   Suppose $y^\alpha$ is a monomial satisfying the property that $y^\alpha
%   t^\beta \in \LT(J) \implies t^\beta \in \LT(J)$ for every $\beta$. Then
%   $y^\alpha \notin \LT(J(t))$ for generic $t$.
% \end{observation}


% \begin{observation}
%   Let $y^\alpha$ be a monomial. If, for each monomial $y^\beta$ 
%   of multidegree strictly smaller than that of $y^\alpha$, $\ltcoeff(y^\beta)$
%   is either $J_0$ or $(1)$, then 

  
% \end{observation}

% The hypotheses of the observation can be interpreted as saying $\LT(J)$ is
% independent of parameters inside multigraded components

% With this choice of monomial ordering, some facts will be useful.
% Let $\Sigma$ be an order ideal of multidegrees, that is a set 
% closed under taking smaller multidegrees, and let $R_\Sigma$ be the sum of the 
% multigraded components corresponding to $\Sigma$.
% We say a family $J(t)$ has
% \emph{leading term ideal independent of parameters on $\Sigma$} if $\LT(J(t))
% \cap R_\Sigma$ is independent of the choice of $t$. 

% \begin{observation}
%   $J(t)$ has leading term ideal independent of parameters on $\Sigma$
%   if and only if $\LT(J)$ has a set of generators $y^{\alpha_i} t^{\beta_i}$
%   where $\beta_i = 0$ when $\alpha_i \in \Sigma$.
%   % In this case, $\LT(J(t)) \cap R_\Sigma = \LT(J)\cap R_\Sigma$.
% \end{observation}

% \begin{observation}
%   Let $J\cap \CC[t_1,\ldots,t_k]$ be prime. Then $\LT(J(t))$ for a generic $t$
%   depends only on $\LT(J)$. 
% \end{observation}

% \begin{observation}
%   Let $y^\alpha$ be a monomial and let $\Sigma$ be the set of multidegrees
%   stictly smaller than the multidegree of $y^\alpha$.
%   If $J$ has leading term ideal independent of parameters on $\Sigma$, 

%   Let $p$ be an element of the reduced Gr\"obner basis of $J$, and $\Sigma$ the
%   set of multidegrees strictly smaller than the degree of $p$. 
% \end{observation}

% % For homogeneous ideals, this property of $I_t$ only depends on the elements of
% % $I_t$ contained in those components


% % Over the course of the ideal enumeration algorithm, it will be required to
% % compute the parameter values $t$ for which a given monomial does not occur in
% % the leading term ideal $I_t$ . 

% % \begin{observation}
% % If
% %   Suppose $X$ is irreducible. Then 
% %   $m t^\alpha \in \LT(J)$ for some $\alpha$ if and only if
% %   $m \in \LT(J(t))$ for generic $t\in X$.
% % \end{observation}
% % \begin{observation}
% %   Suppose $X$ is irreducible. Then 
% %   $m t^\alpha \in \operatorname{LT}(J)$ for some $\alpha$ if and only if
% %   $m \in \operatorname{LT}(J(t))$ for generic $t\in X$.
% % \end{observation}

% % TODO Are there natural conditions on J such that if $X$ is irreducible then
% % the family has constant hilbert function on all of X or just an open subset?

% This observation suggests an algorithm for the task.

% (see, e.g.,
% \code{minimal_relations_killing_leading_term})

\subsubsection{Putting it together}\label{sec:representationlast}

To combine the ideas of \S \ref{sec:borelfixed} and \S \ref{sec:parameterized}
we take as our working ring
$S=\CC[y_1,\ldots,y_n,x_1,\ldots,x_k,t_1,\ldots,t_{k'}]$, where $y_i$ denote the
variables of $A^*$, $B^*$, and $C^*$, $x_i$ are identified with a vector space
basis of $\mathfrak{n}$, and $t_i$ are extra parameters of degree and weight 0.
Here the $y_i$ and $x_i$ satisfy the noncommutative relations described in \S
\ref{sec:borelfixed}, and both sets commute with the $t_i$. The block condition
on the monomial order of \S\ref{sec:borelfixed} here requires that the variable
block $y_1,\ldots,y_n,x_1,\ldots,x_k$ is greater than the variable block
$t_1,\ldots,t_{k'}$.
A family of ideals $I_t$ is representable (see
\S\ref{sec:intro}) when it corresponds to a two-sided ideal $J\subset S$
homogeneously generated (including weight homogeneously) by elements of the
subring $\CC[y_1,\ldots,y_n,t_1,\ldots,t_{k'}]$. 
% TODO technically to agree with intro I should require $J \subset Tperp
The notions of restriction of
families, evaluation at $t$, and trivially missing monomials are carried over
unmodified from \S\ref{sec:parameterized}.

In multidegree $(ijk)$ pick an ordering $(m_i)_i$ of the monomials $m_i =
y^{\alpha_i}$ so that if $\wt(y^{\alpha_i}) \le \wt(y^{\alpha_j})$ in the
partial order, then $i \ge j$ (note the order reversal), and if
$\wt(y^{\alpha_i}) = \wt(y^{\alpha_j})$ and $y^{\alpha_i} < y^{\alpha_j}$,
then $i \le j$. Hence, the last monomial on this list is the biggest monomial of
the smallest weight.
Note, there is no harm in choosing the monomial order on $y_1,\ldots,y_n$ so
that it already satisfies these properties. However, this is not strictly
necessary and could impact the performance of the implementation, so we do not
make this requirement.

This order has the property that
adjoining a homogeneous polynomial $p$ to an
ideal $J$ doesn't change the sets of leading coefficients corresponding to
larger monomials than $\Lm(p)$ in $(m_i)_i$.
That is, for $p$ with $\Lm(p) = m_i$ and $j>i$, the sets
$\{\ltcoeff(q) : \Lm(q) = m_j\}$ corresponding to $J$ and $J+(p)$ are 
identical. 
For such an ordering, and under our new conditions on $J$ we have the following
analogue of observation \ref{missing}:

\begin{observation}\label{missing2}
  Let $J'$ be a restriction of a representable family $J$. % other conditions?
  If $s$ of the largest $m$ monomials of $(m_i)_i$ in multidegree $(ijk)$ are trivially
  missing from $J$, then at least $s$ are trivially missing from $J'$.

%   In particular, if $s$ of the largest $m$ monomials are trivially missing in
%   $J$, then at least $s$ of the largest $m$ monomials are not contained in
%   $\LM(J(t))$ for any $t$.
\end{observation}

The routine \code{get_vorder} chooses a weight basis of $(T^\perp)_{ijk}$ with
pairwise distinct leading monomials and orders them according to the
requirements for the $m_i$ (thus implicitly fixing such a list $(m_i)_i$). 
These orderings are used to organize the calculations in \code{enumerate_tm} and
\code{enumerate_tm_bounded}.

\subsection{Software used}

The code is written in Python 3, using the libraries provided by SageMath.
The implementation of $G$-algebras and their arithmetic and ideal computations
is done under the hood by Plural, a kernel extension of the Singular computer
algebra system.

\section{Program Listing}

<<complete=False>>=
from itertools import *

def check_T_is_stabilized(T,reps):
    a = len(T)
    b,c = T[0].dimensions()

    # Check there is one weight for each basis vector
    assert all(len(wts) == d for d,(wts,_) in zip((a,b,c),reps))
    # Check the given representations of $\mathfrak{n}$ operate on the correct dimensional space
    assert all(x.nrows() == d and x.ncols() == d 
            for d,(_,xs) in zip((a,b,c),reps) for x in xs)

    # Compute roots of the simple roots vectors xs
    simple_roots = []
    for xi in range(len(reps[0][1])):
        for wts,xs in reps:
            if not xs[xi].is_zero():
                i,j = xs[xi].nonzero_positions()[0]
                simple_roots.append(wts[i] - wts[j])
                break

    # Check xs are actally root vectors for the corresponding roots and that 
    # the simple roots agree for each rep in reps
    for wts,xs in reps:
        assert len(simple_roots) == len(xs)
        for root,x in zip(simple_roots,xs):
            for i,j in x.nonzero_positions():
                assert wts[i]-wts[j] == root

    # Check T is weight zero in $A\ot B\ot C$
    for i,m in enumerate(T):
        for j,k in m.nonzero_positions():
            assert (reps[0][0][i] + reps[1][0][j] + reps[2][0][k]).is_zero()
    
    # Check T is closed under $\mathfrak{n}$
    (_,xsA), (_,xsB), (_,xsC) = reps
    for xa,xb,xc in zip(xsA, xsB, xsC):
        xaT = [sum(xa[i,j] * T[j] for j in range(a)) for i in range(a)]
        xbT = [xb*m for m in T]
        xcT = [m*xc.T for m in T]
        # we should have xaT + xbT + xcT = 0
        assert all((m1+m2+m3).is_zero() for m1,m2,m3 in zip(xaT, xbT, xcT))
    
    return simple_roots

def Tinfo(T,reps=None):
    if reps is None:
        Lg,reps = stabilizer_reps_ss(T)

    xs = [ block_diagonal_matrix([x[i] for x,y,h in reps],subdivide=False)
            for i in range(len(reps[0][0])) ]
    hs = [ block_diagonal_matrix([h[i] for x,y,h in reps],subdivide=False)
            for i in range(len(reps[0][2])) ]
    T = np.array(list(map(list,T)))
    vwts = matrix([h.diagonal() for h in hs])
    return T,vwts,xs

@

\code{memoize} is a function decorator used for performance reasons only. A function
decorated \code{@memoize} will compute its result for a particular argument only
once, and future runs with the same argument will return the previously computed
result.

<<complete=False>>=
def memoize(obj):
    cache = obj.cache = {}

    import functools
    @functools.wraps(obj)
    def memoizer(*args, **kwargs):
        if args not in cache:
            cache[args] = obj(*args, **kwargs)
        return cache[args]
    return memoizer

def three_place_ideals_up_to(ba,d=1):
    cd2 = [ ba.enumerate_candidates((1,1,0),tmcs=[(2,1,0),(1,2,0)]) ]
    cd2.append(ba.enumerate_candidates((1,0,1),tmcs=[(2,0,1),(1,0,2)]))
    cd2.append(ba.enumerate_candidates((0,1,1),tmcs=[(0,2,1),(0,1,2)]))
    c111 = []
    for Jxis in product(*cd2):
        Jxi = ba.sum_ideals(Jxis)
        try:
            next(ba.enumerate_tm_bounded((1,1,1),Jxi[0]))
            c111.append(Jxi)
        except StopIteration:
            pass
    if d == 1:
        for Jxi in c111:
            yield Jxi
        return
    schedule = [(2,0,0),(0,2,0),(0,0,2)]
    schedule.extend([tuple(tm) for k in range(3,d+1) 
        for tm in IntegerVectors(k,3)])

    def dfs(Jxi,i): 
        if i == len(schedule):
            yield Jxi
            return
        tm = schedule[i]
        print (tm)
        for Jxiup in ba.enumerate_candidates(tm,[tm[:s]+(tm[s]+1,)+tm[s+1:] for s in range(3)],*Jxi):
            for Jxifull in dfs(Jxiup,i+1):
                yield Jxifull

    for Jxi in c111:
        for Jxifull in dfs(Jxi,0):
            yield Jxifull

@

The Python class \code{BorderApolarity} provides a convenient interface to the
routines of this file which depend on the input data (see \S\ref{sec:input}).
Other than this data, the only additional state tracked by objects of this class
are the previously computed cached results from functions marked
\code{@memoize}.

<<complete=False>>=

class BorderApolarity:
    def __init__(self, Tinfo, r, F = QQ):
        self.T, self.vwts, self.xs = Tinfo
        self.xs = [-x.T for x in self.xs]
        self.vwts = -self.vwts
        self.Bxs = basis_of_lie_algebra(self.xs)
        self.r = r
        self.F = F
        self.nvars = sum(self.T.shape)
        self.nvarsx = self.nvars + len(self.Bxs)
        self.R0 = self.get_ring()
        self.vixs = [0]
        for s in self.T.shape:
            self.vixs.append(self.vixs[-1] + s)

        self.X = matrix([self.x_weight(x) for x in self.xs])
        self.Xixs = self.X.pivots()
        self.Xi = ~self.X[:,self.Xixs]
@

The function \code{get_ring} implements the logic described in
\S\ref{sec:representation}, namely, it forms the $G$-algebra generated by the
variables $a_1,\ldots,a_\ba$, $b_1,\ldots,b_\bb$,
$c_1,\ldots,c_\bc$, $x_1,\ldots,x_k$, $t_1,\ldots,t_{\text{params}}$ subject to the
appropriate commutator relations and with 
degree reverse lexicographic monomial order on the variables 
$a_1,\ldots,a_\ba$, $b_1,\ldots,b_\bb$,
$c_1,\ldots,c_\bc$, $x_1,\ldots,x_k$ and $t_1,\ldots,t_{\text{params}}$ seperately,
with products of monomials between these groups ordered lexicographically. 

The computation of this algebra is expensive, so 
for performance reasons, calling this function actually chooses the
next power of two number of parameters larger than the requested number and
caches the results for the future. 

<<complete=False>>=
    def get_ring(self,params=0):
        if params > 0:
            params = next(1<<k for k in range(32) if 1<<k >= params )
        return self.get_ring_exact(params)

    @memoize
    def get_ring_exact(self, params=0):
        print("get_ring_exact",params)
        if params > 0:
            params = next(1<<k for k in range(32) if 1<<k >= params )
        # should give cached rings of power of two size
        lets = 'abcdefghijklmnopqrsuvwyz'
        B = matrix([x.list() for x in self.Bxs]).T
        A = FreeAlgebra(self.F,['%s%d' % (lets[i],j) for i in range(self.T.ndim)
            for j in range(self.T.shape[i])] + 
                ['x%d'%i for i in range(len(self.Bxs))] + ['t%d' % j for j in range(params)])
        yvs = A.gens()[:sum(self.T.shape)]
        xvs = A.gens()[sum(self.T.shape):sum(self.T.shape)+len(self.Bxs)]
        rels = {}
        for (xv1,x1),(xv2,x2) in combinations(zip(xvs,self.Bxs),2):
            x3 = x2*x1 - x1*x2
            if not x3.is_zero():
                xv3 = sum(e*yv for e,yv in zip(B.solve_right(vector(x3.list())).list(),xvs))
                rels[xv2*xv1] = xv1*xv2 + xv3
        for (xv,x),(yi,yv) in product(zip(xvs,self.Bxs),enumerate(yvs)):
            xy = x*vector(self.F,self.Bxs[0].nrows(),{yi:1})
            if not xy.is_zero():
                xyv = sum(e*yv for e,yv in zip(xy.list(),yvs))
                rels[xv*yv] = yv*xv + xyv
        order = TermOrder('degrevlex',sum(self.T.shape)+len(self.Bxs))
        if params > 0:
            order = order + TermOrder('degrevlex',params)
        return A.g_algebra(rels,order=order)
@

\code{get_vorder} takes a multidegree $ijk$ as argument and 
computes a basis of 
$(T^\perp)_{ijk}$ as described at the end of \S\ref{sec:representationlast}.

<<complete=False>>=
    @memoize
    def get_vorder(self, tm):
        if max(tm) == 1:
            tone = [i for i in range(len(tm)) if tm[i] == 1]
            tzero = [i for i in range(len(tm)) if tm[i] == 0]
            Tr = self.T.transpose(tzero+tone)
            Tr = Tr.reshape(prod(Tr.shape[:len(tzero)]),-1)
            Tr = matrix(self.F,Tr)

        ivs = [IntegerVectors(t,self.T.shape[ti]) for ti,t in enumerate(tm)]
        from operator import concat
        vorder = {}
        for v in cartesian_product(ivs):
            v = reduce(concat,map(tuple,v))
            wt = tuple(self.vwts*vector(v))
            vorder.setdefault(wt,[]).append(v)
        mon = lambda m: self.R0.prod(x**k for k,x in zip(m,self.R0.gens()) if k>0)
        vorder = sorted(vorder.items(),key=lambda wtvs:
                -self.total_order_sort_key(wtvs[0]))
        allvs = []
        vsl = []
        for vi,(wt,vs) in enumerate(vorder):
            vs.sort(key=mon,reverse=True)
            if max(tm) == 1: # restrict to Tperp
                inc = []
                for v in vs:
                    vix = 0
                    for i in tone:
                        vix *= self.T.shape[i]
                        vix += next(j for j in range(self.T.shape[i]) if
                                v[sum(self.T.shape[:i])+j] == 1)
                    inc.append([1 if i==vix else 0 for i in range(Tr.ncols())])
                K = (Tr*matrix(inc).T).right_kernel_matrix()
                vs = [sum(e*mon(vs[i]) for i,e in enumerate(r)) for r in K]
            else:
                vs = [mon(v) for v in vs]
            allvs.extend(vs)
            vsl.extend([len(allvs)]*len(vs))
        return (allvs,vsl)


    def x_weight(self, x):
        i,j = x.nonzero_positions()[0]
        wt = tuple(self.vwts.column(i)-self.vwts.column(j))
        for i,j in x.nonzero_positions()[1:]:
            assert wt == tuple(self.vwts.column(i)-self.vwts.column(j))
        return wt

    def weight_le(self, wta, wtb):
        dwt = vector(self.F,map(sub,wtb,wta))
        u = dwt * self.Xi
        return all(e >= 0 for e in u) and u*self.X == dwt

    # This should be anything consistent with the partial order given by
    # weight_le. Determines the order the algorithm tries to fill weight spaces
    def total_order_sort_key(self, wt):
        return sum(vector(self.F,[wt[i] for i in self.Xixs])*self.Xi)

    def lm(self, p, toR0 = False):
        R = self.R0 if toR0 else p.parent()
        if p.is_zero():
            return R.zero()
        return R.prod(R.gen(x)**k for x,k in 
                p.lm().exponents()[0][:self.nvars].sparse_iter())

@

\code{minimal_relations_killing_leading_term} implements the recursive procedure
described in \S\ref{sec:parameterized} and computes the smallest restriction of
the input family $J$ so that in the result $\Lm(p)$ is trivially missing.

<<complete=False>>=

    # J assumed to be twostd(), and returned ideals are also twostd
    def minimal_relations_killing_leading_term(self,J,p):
        same = True
        while True:
            teqs = []
            for q in J.gens():
                if not self.lm(q).is_constant() and \
                        self.R0.monomial_divides(self.lm(q,True),self.lm(p,True)):
                    teqs.append(q.coefficient(self.lm(q)))
            if len(teqs) == 0:
                return (J,same)
            else:
                J = (J+teqs).twostd()
                same = False
@

\code{enumerate_candidates} 

<<complete=False>>=

    def enumerate_candidates(self,tm,tmcs,J0=None,xi=0):
        for J,yi in self.enumerate_tm(tm,J0,xi):
            ok = True
            tmnt = [tmcs[0]]
            for tmc in tmcs[1:]:
                try:
                    Je = next(self.enumerate_tm_bounded(tmc,J))
                    if J != Je:
                        tmnt.append(tmc)
                except StopIteration:
                    ok = False
                    break
            if ok:
                Js = [J]
                for tmc in tmnt:
                    Js = list(chain.from_iterable(self.enumerate_tm_bounded(tmc,Jeq)
                        for Jeq in Js))
                for Jeq in Js:
                    yield (Jeq,yi)
@

This is the fundamental computation of ideal enumeration.

<<complete=False>>=

    def enumerate_tm(self, tm, J=None, xi=0, checkintermediate=False):
        if J is None:
            J = self.get_ring().ideal(side='twosided')
        Jorig = J
        J += [p for i,e in enumerate(tm) for p in
                self.all_monomials((0,)*i+(e+1,)+(0,)*(len(tm)-i-1),J.ring())]
        J = J.twostd()

        vs, vsl = self.get_vorder(tm)
        vsb = [next((j for j in vsl[i::-1] if j != vsl[i]),0) for i in range(len(vsl))]

        lp = self.get_linear_program((tm,))
        # lp = self.get_linear_program((tm,),((2,1,0),(1,2,0)))

        for i,p in enumerate(vs):    
            if J.reduce(liftR(p,J.ring())) != liftR(p,J.ring()):
                # p.lm() definitely already in, cf case 1 below
                lp.set_min(lp[p.lm()],1.0)
                lp.set_max(lp[p.lm()],1.0)
            else:
                lp.set_min(lp[p.lm()],0.0)
                lp.set_max(lp[p.lm()],1.0)

        from sage.numerical.mip import MIPSolverException

        def dfs(ii,J,xi,r):
            if checkintermediate and ii > 0 and ii == vsl[ii-1] and\
                    any(lp.get_max(lp[vs[i].lm()]) == 0.0 for i in range(vsb[ii-1],vsl[ii-1])) and\
                    any(lp.get_min(lp[vs[i].lm()]) == 1.0 for i in range(vsb[ii-1],vsl[ii-1])):
                J = J.twostd()
                for p in vs[:ii]:
                    if lp.get_max(lp[p.lm()]) == 0.0:
                        J, _ = self.minimal_relations_killing_leading_term(J,p)
                        if 1 in J:
                            return

            if ii == len(vs):
                assert r == 0
                yield (J,xi)
                return

            ix = vsb[ii]+vsl[ii]-ii-1

            # case 1, vs[ii].lm() already in the leading term ideal, move on
            if lp.get_min(lp[vs[ix].lm()]) == 1.0:
                for JJ in dfs(ii+1,J,xi,r):
                    yield JJ
                return

            try:
                lp.set_objective(-lp[vs[ix].lm()])
                lo = -lp.solve()
                lp.set_objective(lp[vs[ix].lm()])
                hi = lp.solve()
            except MIPSolverException:
                return

            print ('%s%d' % (' '*ii,r))
            if r == 0 and ii > 0 and ii == vsl[ii-1]:
                J = J + [liftR(p,J.ring()) for p in vs[ii:]]
                yield (J,xi)
                return

            # case 2: vs[ii].lm() is not in the leading term ideal
            if lo == 0.0:
                lp.set_max(lp[vs[ix].lm()],0.0)
                for JJ in dfs(ii+1,J,xi,r-1):
                    yield JJ
                lp.set_max(lp[vs[ix].lm()],1.0)

            # case 3: put vs[ii].lm() in the leading term ideal
            if hi == 1.0:
                cur_params = J.ring().ngens() - self.nvarsx
                needed_params = xi + len([j for j in range(ix+1,vsl[ix]) if 
                    lp.get_min(lp[vs[j].lm()]) == 0.0])
                if needed_params > cur_params:
                    R = self.get_ring(needed_params)
                    J = R.ideal([liftR(p,R) for p in J.gens()])
                R = J.ring()

                p = liftR(vs[ix],R) + R.sum(liftR(vs[j],R)*R.gen(self.nvarsx+xi+ji) 
                        for ji,j in enumerate(j for j in range(ix+1,vsl[ix]) if
                        lp.get_min(lp[vs[j].lm()]) == 0.0))

                lp.set_min(lp[vs[ix].lm()],1.0)
                for JJ in dfs(ii+1,J+p,needed_params,r):
                    yield JJ
                lp.set_min(lp[vs[ix].lm()],0.0)

        for I,yi in dfs(0,J,xi,self.r - self.tm_codim_tperp(tm)):
            I = I.twostd()
            for p in vs:
                if lp.get_max(lp[p.lm()]) == 0.0:
                    I, _ = self.minimal_relations_killing_leading_term(I,p)
                    if 1 in I:
                        break
            if 1 in I:
                continue

            I = I.ring().ideal([p for p in I.gens() if not p.is_zero() and 
                all([e<=f for e,f in zip(self.polynomial_tm(p),tm)])])
            I += [liftR(p,I.ring()) for p in Jorig.gens()]
            I,yi = self.quick_simplify(I)
            I = I.twostd()
            yield (I,yi)

    # J assumed to be twostd
    def enumerate_tm_bounded(self, tm, J):
        # J += [p for i,e in enumerate(tm) for p in
        #         self.all_monomials((0,)*i+(e+1,)+(0,)*(len(tm)-i-1),J.ring())]

        vs,_ = self.get_vorder(tm)
        vs = [p(J.ring().gens()[:p.parent().ngens()]) for p in vs]

        def dfs(ii,J,r,checkedIs):
            # print ('%s%d %d' % (' '*ii,ii,r))
            if r == 0:
                yield J
                return
            if ii == len(vs):
                return

            # case 1, vs[ii].lm() is in the leading term ideal, no backtrack needed
            if J.reduce(vs[ii]).lm() != vs[ii].lm():
                for I in dfs(ii+1,J,r,checkedIs):
                    yield I
                return

            already_in_remaining = 0
            for p in vs[ii:]:    
                if J.reduce(p).lm() != p.lm():
                    already_in_remaining += 1 
            if len(vs) - ii - already_in_remaining < r:
                return

            Jnext, same = self.minimal_relations_killing_leading_term(J,vs[ii])

            # case 2: vs[ii].lm() is not in the leading term ideal, no backtrack needed
            if same:
                for I in dfs(ii+1,J,r-1,checkedIs):
                    yield I
                return

            if any(Jnext <= Jchecked for Jchecked in checkedIs):
                # case 3: proposed relations are implied by relations which will
                # be checked in an earlier case 5; no need to check them now.
                # Don't assume vs[ii].lm() in the leading term ideal and don't
                # backtrack this decision
                for I in dfs(ii+1,J,r,checkedIs):
                    yield I
                return 

            # case 4: proceed without assuming vs[ii].lm() in the leading
            # term ideal, and dont check equations implied by Inew in the future
            # (such will be covered by case 5 here)
            case5needed = True
            for I in dfs(ii+1,J,r,checkedIs+[Jnext]):
                if I <= Jnext:
                    case5needed = False
                yield I

            # case 5: add equations excluding vs[ii].lm() out of the leading
            # term ideal. If we have already encountered a solution which is more
            # general than Inew, we need not search more
            if case5needed:
                for I in dfs(ii+1,Jnext,r-1,checkedIs):
                    yield I

        for I in dfs(0,J,self.r - self.tm_codim_tperp(tm),[]):
            I,_ = self.quick_simplify(I)
            # I = I.ring().ideal([p for p in I.gens() if not p.is_zero() and 
            #     all([e<=f for e,f in zip(self.polynomial_tm(p),tm)])],side='twosided')
            yield I

    @memoize
    def tm_dim(self, tm):
        return prod(binomial(d+t-1,t) for t,d in zip(tm,self.T.shape))

    @memoize
    def tm_dim_tperp(self, tm):
        if max(tm) > 1:
            return self.tm_dim(tm)
        else:
            return len(self.get_vorder(tm)[0])

    @memoize
    def tm_codim_tperp(self, tm):
        return self.tm_dim(tm) - self.tm_dim_tperp(tm)

    def polynomial_tm(self, p):
        e = p.exponents()[0]
        return tuple(sum(k for _,k in e[a:b].sparse_iter()) 
                for a,b in zip(self.vixs,self.vixs[1:]))

    def polynomial_weight(self, p):
        e = p.exponents()[0]
        return tuple(sum(k*self.vwts[:,xi] for xi,k in e.sparse_iter()).list())

    def all_monomials(self, tm, R=None):
        if R is None:
            R = self.get_ring()
        for y in cartesian_product([IntegerVectors(a,d) 
                for a,d in zip(tm,self.T.shape) ]):
            yield R.prod(x**k for k,x in 
                    zip((k for e in y for k in e),R.gens()) if k>0)

    @memoize
    def get_linear_program(self, tms, tms_triv=()):
        prog = MixedIntegerLinearProgram()
        prog.set_binary(prog.default_variable())
        # # if set_real, be sure to change exact comparisons to within machine precision
        # prog.set_real(prog.default_variable())

        # constraint that all of ps implies at least one of the qs
        def le_constraint(ps,qs):
            prog.add_constraint(prog.sum(1-prog[p.lm()] for p in ps) +\
                prog.sum(prog[p.lm()] for p in qs) >= 1)
        for tm in tms:
            vs,vsl = self.get_vorder(tm)
            prog.add_constraint(prog.sum(prog[p.lm()] for p in vs) == 
                    max(self.tm_dim(tm) - self.r,0))
        for tm in tms_triv:
            vs,vsl = self.get_vorder(tm)
            prog.add_constraint(prog.sum(prog[p.lm()] for p in vs) <= 
                    max(self.tm_dim(tm) - self.r,0))
        P = Poset((tms+tms_triv,lambda a,b: all(i<=j for i,j in zip(a,b))))
        for tm,tmr in P.cover_relations():
            for v in self.get_vorder(tm)[0]:
                for y in self.all_monomials(tuple(map(sub,tmr,tm))):
                    le_constraint([v],[v*y])
        if len(tms) == 0:
            return prog
        
        tmm = reduce(lambda tma,tmb: tuple(map(max,tma,tmb)),tms+tms_triv)
        def get_ps_from_coords(pis):
            R = self.get_ring(sum(self.get_vorder(tm)[1][ii]-ii-1 
                for tm,ii in pis))
            xi = 0
            ps = []
            for tm,ii in pis:
                vs,vsl = self.get_vorder(tm)
                ps.append(liftR(vs[ii],R) + R.sum(liftR(p,R)*t for 
                        p,t in zip(vs[ii+1:vsl[ii]], R.gens()[self.nvarsx+xi:])))
                xi += vsl[ii] - ii - 1
            Jbound = R.ideal([p for i,e in enumerate(tmm) for p in
                self.all_monomials((0,)*i+(e+1,)+(0,)*(len(tm)-i-1),R)],side='twosided')
            return ps,Jbound

        def raising_constraints(ps,J):
            for q in J.gens():
                if self.polynomial_tm(q) in tms+tms_triv:
                    oneof = []
                    have_constant = False
                    while not q.is_zero():
                        oneof.append(self.lm(q,True))
                        if q.coefficient(self.lm(q)).is_constant():
                            have_constant = True
                            break
                        q -= q.coefficient(self.lm(q))*self.lm(q)
                    if have_constant:
                        le_constraint([self.lm(p,True) for p in ps],oneof)

        for tm in tms:
            for i,pend in enumerate(self.get_vorder(tm)[1]):
                if i != pend-1:
                    continue
                print self.polynomial_weight(self.get_vorder(tm)[0][i])
                ps,Jbound = get_ps_from_coords([(tm,j) for j in range(i,pend)])
                for k in range(1,len(ps)+1):
                    for qs in combinations(ps,k):
                        J = (Jbound+qs).twostd()
                        raising_constraints(qs,J)

        return prog

    def bounded_gb(self, J, tm):
        J += [p for i,e in enumerate(tm) for p in
                self.all_monomials((0,)*i+(e+1,)+(0,)*(len(tm)-i-1),J.ring())]
        gb = J.twostd().gens()
        gb = [p for p in gb if all(a<=b for a,b in zip(self.polynomial_tm(p),tm))]
        return gb
    
    # For testing purposes
    # This gives the monomials not in the leading term ideal for a generic point
    # in the family of ideals corresponding to J. If the family J is not
    # irreducible, this gives the intersection of this set of monomials over all
    # the irreducible components of J
    # it is assumed that the family J is nonempty (1 not in J)
    def generic_codim(self,J,tm):
        msin = set()
        for p in J.gens():
            m = self.lm(p,True)
            if not m.is_constant(): # otherwise a defining equation of the family
                for n in self.all_monomials(map(sub,tm,self.polynomial_tm(m))):
                    msin.add(m*n)
        return [m for m in self.all_monomials(tm) if m not in msin]

    def sum_ideals(self,Jxis):
        sxis = sum(xi for J,xi in Jxis)
        R = self.get_ring(sxis)
        gens = []
        xcum = 0
        for J,xi in Jxis:
            gens.extend([p(R.gens()[:self.nvarsx] +
                R.gens()[self.nvarsx+xcum:self.nvarsx+xcum+xi] +
                (R.zero(),) * (J.ring().ngens()-self.nvarsx-xi))
                for p in J.gens()])
            xcum += xi
        return (R.ideal(gens,side='twosided'),xcum)

    def quick_simplify(self,I):
        R = I.ring()
        vals = {}
        tis = set()
        for p in I.gens():
            tiscur = set()
            for e in p.exponents():
                for i in e[self.nvarsx:].nonzero_positions():
                    tiscur.add(i)
            if len(tiscur) == 1 and self.lm(p).is_constant() and p.degree() == 1:
                i = tiscur.pop()
                t0 = -p.monomial_coefficient(p.parent().one()) /\
                    p.monomial_coefficient(p.parent().gen(self.nvarsx + i))
                vals[i] = t0
            else:
                tis = tis.union(tiscur)
        subs = list(R.gens()[:self.nvarsx])
        j = self.nvarsx
        for i in range(R.ngens()-self.nvarsx):
            if i in tis:
                subs.append(R.gen(j))
                j += 1
            elif i in vals:
                subs.append(R(vals[i]))
            else:
                subs.append(R.zero())
        I = R.ideal([p(*subs) for p in I.gens()],side='twosided')
        return (I,len(tis))

def liftR(p,R):
    if p.parent() is R:
        return p
    return p(R.gens()[:p.parent().ngens()]+(R.zero(),)*(p.parent().ngens()-R.ngens()))

def basis_of_lie_algebra(xs):
    B = copy(xs)
    Q = copy(xs)
    while len(Q) > 0:
        y = Q.pop()
        for x in xs:
            z = x*y-y*x
            if matrix(t.list() for t in B+[z]).rank() > len(B):
                B.append(z)
                Q.append(z)
    return B
@


\begin{thebibliography}{9}
  \bibitem{levendovsky}
  Levandovskyy, V. Non-commutative Computer Algebra for polynomial algebras:
  Gr\"obner bases, applications and implementation. Doctoral Thesis,
  Universit\"at Kaiserslautern, 2005. Available online at http://kluedo.ub.uni-kl.de/volltexte/2005/1883/.articular 
\end{thebibliography}
\end{document}
